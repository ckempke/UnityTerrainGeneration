{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Runtime Terrain Generation in Unity I've always loved open world games, with their illusion of complete freedom of movement in a vast world ready for exploration. And as a developer, I've similarly been a fan of procedural generation of game environments: the notion that the game can\u2014through application of rules\u2014generate its own content. In the best scenarios, this gives way to emergent behavior , in which those rules combine in ways that are more than the sum of their parts, and can produce results (pleasantly) surprising even to the developer. (Contrast with bugs , which are results unpleasantly surprising to the developer...) The logical endpoint of this are games like No Man's Sky , in which virtually the entire world is procedurally generated. As a developer, one of the attractions of such systems is that a small team--perhaps even an individual--can create a \"large\" game in this way. Since, despite what the scale tells me, I am an individual, and I've now got time to look into projects like this, I'm combining an effort to learn the Unity game engine with a desire to push some boundaries of procedural design. Will this turn into something more than some musings on the web? Who knows? That's the wonder of it. Another wonder of the modern internet is that you never know who's going to wander by, courtesy of Bing, Google, or the world's most specific typo. If you're looking for me, contact information is over at https://www.chriskempke.com --Chris Tools This site is being hosted at Github Pages, but it's not using their Jekyll parser. Instead, I'm using Docsify, with the Mermaid extensions turned on. Mermaid allows graphs such as flowcharts and sequence diagrams: flowchart TB c1-->a2 subgraph one a1-->a2 end subgraph two b1-->b2 end subgraph three c1-->c2 end one --> two three --> two two --> c2 I also enable KaTeX, which allows both inline ( \\(c = \\pm\\sqrt{a^2 + b^2}\\) ) and callout LaTeX mathematics symbols: \\[ \\mathbf{V}_1 \\times \\mathbf{V}_2 = \\begin{vmatrix} \\mathbf{i} & \\mathbf{j} & \\mathbf{k} \\\\ \\frac{\\partial X}{\\partial u} & \\frac{\\partial Y}{\\partial u} & 0 \\\\ \\frac{\\partial X}{\\partial v} & \\frac{\\partial Y}{\\partial v} & 0 \\\\ \\end{vmatrix} \\] Docsify itself parses Markdown files of various sorts to produce the HTML display you're looking at now, including the sidebar to the left (or in the hamburger menu if you're browsing on mobile) and the live text search.","title":"Home"},{"location":"#runtime-terrain-generation-in-unity","text":"I've always loved open world games, with their illusion of complete freedom of movement in a vast world ready for exploration. And as a developer, I've similarly been a fan of procedural generation of game environments: the notion that the game can\u2014through application of rules\u2014generate its own content. In the best scenarios, this gives way to emergent behavior , in which those rules combine in ways that are more than the sum of their parts, and can produce results (pleasantly) surprising even to the developer. (Contrast with bugs , which are results unpleasantly surprising to the developer...) The logical endpoint of this are games like No Man's Sky , in which virtually the entire world is procedurally generated. As a developer, one of the attractions of such systems is that a small team--perhaps even an individual--can create a \"large\" game in this way. Since, despite what the scale tells me, I am an individual, and I've now got time to look into projects like this, I'm combining an effort to learn the Unity game engine with a desire to push some boundaries of procedural design. Will this turn into something more than some musings on the web? Who knows? That's the wonder of it. Another wonder of the modern internet is that you never know who's going to wander by, courtesy of Bing, Google, or the world's most specific typo. If you're looking for me, contact information is over at https://www.chriskempke.com --Chris","title":"Runtime Terrain Generation in Unity"},{"location":"#tools","text":"This site is being hosted at Github Pages, but it's not using their Jekyll parser. Instead, I'm using Docsify, with the Mermaid extensions turned on. Mermaid allows graphs such as flowcharts and sequence diagrams: flowchart TB c1-->a2 subgraph one a1-->a2 end subgraph two b1-->b2 end subgraph three c1-->c2 end one --> two three --> two two --> c2 I also enable KaTeX, which allows both inline ( \\(c = \\pm\\sqrt{a^2 + b^2}\\) ) and callout LaTeX mathematics symbols: \\[ \\mathbf{V}_1 \\times \\mathbf{V}_2 = \\begin{vmatrix} \\mathbf{i} & \\mathbf{j} & \\mathbf{k} \\\\ \\frac{\\partial X}{\\partial u} & \\frac{\\partial Y}{\\partial u} & 0 \\\\ \\frac{\\partial X}{\\partial v} & \\frac{\\partial Y}{\\partial v} & 0 \\\\ \\end{vmatrix} \\] Docsify itself parses Markdown files of various sorts to produce the HTML display you're looking at now, including the sidebar to the left (or in the hamburger menu if you're browsing on mobile) and the live text search.","title":"Tools"},{"location":"Background/","text":"Background This paper is an investigation into natural terrain generation in the Unity game engine, meaning environments that conform to the expected geological, botanical, and other attributes of the \u201creal world\u201d (or whatever world\u2019s expectations we\u2019re trying to render) without being directly sampled from it. Terrain generation is applicable to a number of fields, but primarily computer games and simulations. It\u2019s often desirable to have \u201creal-world-like,\u201d yet still fictitious settings for player interaction, or be able to generate \u201cprobable\u201d terrains for unexplored areas that we wish to answer questions about (or land a spacecraft on). The exact usage often doesn\u2019t matter\u2014and Unity\u2019s primary use is for games\u2014so we\u2019ll use \u201cgame\u201d as a catch-all term for the rest of this discussion. Geology, Biome, and Water A \"Terrain\" as we customarily think of it is made up of at least two very high-level properties. First, we have the \"Geology,\" which determines the physical structure of the \"ground\" in the terrain. Examples include \"mountains\", \"hills\", \"plains\", and more exotic structures like canyons, badlands, moors, buttes, plateaus, land bridges, caves, etc. We can even stretch the word \u201cnatural\u201d to the breaking point to include things like Avatar\u2019s air-floating islands for magical worlds. In Unity's built-in terrain objects, geology is represented by the components related to the mesh: the mesh itself, as well as colliders, heightmaps, nav agents, and the like. Second, we have the \"Biome,\" which is associated with the (generally) biological details of an area. Examples here would be \"swamp\", \"sea\", \"lake\", \"desert\", \"barren\", \"forest,\" and many more. Unity's terrain objects include these as the \"trees\" and \"details\" components. Note that there\u2019s some fuzziness about \u201cbiological\u201d here. Things like small rock formations, scattered stones, stalactites and stalagmites, and other \u201csmall mineralogical\u201d things aren\u2019t biological, but they\u2019d generally be handled in a manner similar to the locating of plants, and hence lumped into the biome. \u201cWater\u201d (or \u201chydrology\u201d) is a weird component which could be considered either geology or biome, both, or entirely independent. How a game or simulation deals with it will largely depend on whether water is a \"decoration\" or an interactive environment of its own. Unity itself shares this ambiguity, and has generally just given up on implementing water as a standard part of the engine in the early-2020\u2019s versions of the engine. We\u2019ll consider it separately just because many implementations are likely to. For example, consider this screenshot from Bethesda Softwerks's Skyrim:Enhanced Edition .[^1] The shape of the world around us would be the geology, including the terraced rocks, sloping shores, and even the (underwater) river bed. The river itself is of course water, and most of the rest of what we see would be the biome: the trees, the grass, the large stump on the opposite shore, and maybe even some of those smaller rocks areound the river. It's common in games today to combine the two (usually by including geology as part of the biome), and certainly they're often overlapping concepts. But keeping them separate helps is in a couple of ways. First, they're handled at very different parts of the terrain generation process. Second, being able to combine and apply different combinations lets us re-use components to create flexibility. For example, a relatively flat terrain might be a swamp, desert, moor, plain, wheatfield, or several other things depending on which biome it\u2019s paired with. Similarly, a high-altitude biome might be reasonably applied to multiple \u201cmountain\u201d geologies and even things like high meadows. Any categorizations we use are likely to be fuzzy, and when we encounter such ambiguity, we'll likely just default to \"whatever makes the implemenation easier.\" For specific examples: Are the smaller rocks along the river shore part of the geology, or part of the biome? The answer might depend on our game engine, but if we were implementing this in Unity, we could be reasonably certain that the larger \"shape\" of the terrain would be implemented as a terrain object (or some similar standin, see the later discussions of voxel worlds) and hence geology, and the \"lumpy\" rocks would be details built in (as would any place where the rocks overhang the world below, since a Unity terrain object cannot represent overhangs). More generally, how about the grass and small plants? There's two types here. The more interesting (to the player) kind that has three-dimensional shape (even if it's represented by a billboard), and the kind that's just \"painted\" onto the ground. They're implemented in most game engines by at least three different subsystems: textures : which make up the \"paint job\" of the actual polygons billboards :that show a two-dimensional illusion of three dimensions by insuring the textured face always faces the player. These are used as a way to save valuable polygons by not building 3d meshes of objects that are unimportant, vast in quantity, or distant meshes :that represent things that need 3d physicality in the world (and themselves are textured). This would be things like rocks on which the player can sit or stand; trees they can climb, cut down, or must avoid; and really any non-terrain object that the player needs to be able to see from all sides. (Note: Playing with markdown, here's the same thing as a table!) Type Unity Type Description Texture Spryte/Material The images used to paint the polygons of a mesh Billboard Mesh + Material a 2-dimensional illusion of a 3-dimensional object, where the single polygon face (usually a quad) faces the player at all times Meshes Mesh A 3D object made up of vertices, edges, polygons, and textures (and possibly other elements) for drawing an \"object\" in the virtual world It is not atypical for a single \"object\" to be represented at various times by all of these methods. A forest sufficiently distant that a player is unlikely to be resolving (or caring about) individual trees may well just be a \"trees texture\" painted on the terrain itself. As the player gets closer, the trees will individualize as billboards, and as meshes when the player gets closer still. Modern game engines have mechanisms to manage this magic, reducing the \"jumping\" as billboard suddenly becomes a mesh as the player approaches. [^1]: Note that Skyrim is not a Unity game (and in fact, most of the examples in these early chapters aren't), it's just used as an example of the types of things we might like to build. Skyrim is built using Bethesda Softwerks's Creation Engine . Unity Terrain GameObjects The Unity engine provides a high-level game object called \u201cTerrain.\u201d Unity Terrain objects consist of both geology (represented as a heightmap), and biome (represented as a \u201ctrees\u201d collection and a \u201cdetails\u201d collection). It does not handle water directly (and since about 2019 Unity has not included the \u201cStandard Assets\u201d collections that used to provide the easiest implementation), so water features are imposed as separate game objects, usually as one or more geometric volumes or a simple \u201csurfaces\u201d at a particular altitude, depending on the needs of the game.","title":"Background"},{"location":"Background/#background","text":"This paper is an investigation into natural terrain generation in the Unity game engine, meaning environments that conform to the expected geological, botanical, and other attributes of the \u201creal world\u201d (or whatever world\u2019s expectations we\u2019re trying to render) without being directly sampled from it. Terrain generation is applicable to a number of fields, but primarily computer games and simulations. It\u2019s often desirable to have \u201creal-world-like,\u201d yet still fictitious settings for player interaction, or be able to generate \u201cprobable\u201d terrains for unexplored areas that we wish to answer questions about (or land a spacecraft on). The exact usage often doesn\u2019t matter\u2014and Unity\u2019s primary use is for games\u2014so we\u2019ll use \u201cgame\u201d as a catch-all term for the rest of this discussion.","title":"Background"},{"location":"Background/#geology-biome-and-water","text":"A \"Terrain\" as we customarily think of it is made up of at least two very high-level properties. First, we have the \"Geology,\" which determines the physical structure of the \"ground\" in the terrain. Examples include \"mountains\", \"hills\", \"plains\", and more exotic structures like canyons, badlands, moors, buttes, plateaus, land bridges, caves, etc. We can even stretch the word \u201cnatural\u201d to the breaking point to include things like Avatar\u2019s air-floating islands for magical worlds. In Unity's built-in terrain objects, geology is represented by the components related to the mesh: the mesh itself, as well as colliders, heightmaps, nav agents, and the like. Second, we have the \"Biome,\" which is associated with the (generally) biological details of an area. Examples here would be \"swamp\", \"sea\", \"lake\", \"desert\", \"barren\", \"forest,\" and many more. Unity's terrain objects include these as the \"trees\" and \"details\" components. Note that there\u2019s some fuzziness about \u201cbiological\u201d here. Things like small rock formations, scattered stones, stalactites and stalagmites, and other \u201csmall mineralogical\u201d things aren\u2019t biological, but they\u2019d generally be handled in a manner similar to the locating of plants, and hence lumped into the biome. \u201cWater\u201d (or \u201chydrology\u201d) is a weird component which could be considered either geology or biome, both, or entirely independent. How a game or simulation deals with it will largely depend on whether water is a \"decoration\" or an interactive environment of its own. Unity itself shares this ambiguity, and has generally just given up on implementing water as a standard part of the engine in the early-2020\u2019s versions of the engine. We\u2019ll consider it separately just because many implementations are likely to. For example, consider this screenshot from Bethesda Softwerks's Skyrim:Enhanced Edition .[^1] The shape of the world around us would be the geology, including the terraced rocks, sloping shores, and even the (underwater) river bed. The river itself is of course water, and most of the rest of what we see would be the biome: the trees, the grass, the large stump on the opposite shore, and maybe even some of those smaller rocks areound the river. It's common in games today to combine the two (usually by including geology as part of the biome), and certainly they're often overlapping concepts. But keeping them separate helps is in a couple of ways. First, they're handled at very different parts of the terrain generation process. Second, being able to combine and apply different combinations lets us re-use components to create flexibility. For example, a relatively flat terrain might be a swamp, desert, moor, plain, wheatfield, or several other things depending on which biome it\u2019s paired with. Similarly, a high-altitude biome might be reasonably applied to multiple \u201cmountain\u201d geologies and even things like high meadows. Any categorizations we use are likely to be fuzzy, and when we encounter such ambiguity, we'll likely just default to \"whatever makes the implemenation easier.\" For specific examples: Are the smaller rocks along the river shore part of the geology, or part of the biome? The answer might depend on our game engine, but if we were implementing this in Unity, we could be reasonably certain that the larger \"shape\" of the terrain would be implemented as a terrain object (or some similar standin, see the later discussions of voxel worlds) and hence geology, and the \"lumpy\" rocks would be details built in (as would any place where the rocks overhang the world below, since a Unity terrain object cannot represent overhangs). More generally, how about the grass and small plants? There's two types here. The more interesting (to the player) kind that has three-dimensional shape (even if it's represented by a billboard), and the kind that's just \"painted\" onto the ground. They're implemented in most game engines by at least three different subsystems: textures : which make up the \"paint job\" of the actual polygons billboards :that show a two-dimensional illusion of three dimensions by insuring the textured face always faces the player. These are used as a way to save valuable polygons by not building 3d meshes of objects that are unimportant, vast in quantity, or distant meshes :that represent things that need 3d physicality in the world (and themselves are textured). This would be things like rocks on which the player can sit or stand; trees they can climb, cut down, or must avoid; and really any non-terrain object that the player needs to be able to see from all sides. (Note: Playing with markdown, here's the same thing as a table!) Type Unity Type Description Texture Spryte/Material The images used to paint the polygons of a mesh Billboard Mesh + Material a 2-dimensional illusion of a 3-dimensional object, where the single polygon face (usually a quad) faces the player at all times Meshes Mesh A 3D object made up of vertices, edges, polygons, and textures (and possibly other elements) for drawing an \"object\" in the virtual world It is not atypical for a single \"object\" to be represented at various times by all of these methods. A forest sufficiently distant that a player is unlikely to be resolving (or caring about) individual trees may well just be a \"trees texture\" painted on the terrain itself. As the player gets closer, the trees will individualize as billboards, and as meshes when the player gets closer still. Modern game engines have mechanisms to manage this magic, reducing the \"jumping\" as billboard suddenly becomes a mesh as the player approaches. [^1]: Note that Skyrim is not a Unity game (and in fact, most of the examples in these early chapters aren't), it's just used as an example of the types of things we might like to build. Skyrim is built using Bethesda Softwerks's Creation Engine .","title":"Geology, Biome, and Water"},{"location":"Background/#unity-terrain-gameobjects","text":"The Unity engine provides a high-level game object called \u201cTerrain.\u201d Unity Terrain objects consist of both geology (represented as a heightmap), and biome (represented as a \u201ctrees\u201d collection and a \u201cdetails\u201d collection). It does not handle water directly (and since about 2019 Unity has not included the \u201cStandard Assets\u201d collections that used to provide the easiest implementation), so water features are imposed as separate game objects, usually as one or more geometric volumes or a simple \u201csurfaces\u201d at a particular altitude, depending on the needs of the game.","title":"Unity Terrain GameObjects"},{"location":"Requirements/","text":"Requirements If the goal is to build something, it helps to know what we're trying to build. I've called this section \"Requirements,\" but this is an experimental project, so what we're listing here are really \"aspirational goals.\" Not all of these may be achievable, reasonable, or even technically possible. But we still want to describe what an \"ideal\" system would look like. For the moment, we're going to consider just Geology (that is, just the shape of the terrain, not what's on/in it. Target Software Platform Unity3D initially. Presumedly many of the concepts would move to other engines (particularly Unreal), but we're going to take advantage of whatever technologies Unity offers us without much concern for whether or not they're portable. Scalability Our first requirement is that this system be scalable to different hardware. Our specific target is 90/90/90: 90 frames per second 90% of the time on 90th percentile gaming hardware (that is, a PC gaming system which can outperform 90 percent of all PC game systems.) Why exclude 90% of PCs? First, because the tail on systems is very long: See Steam's System Surveys here for samples. The bottom half or so of these systems aren't playing modern games much. But more importantly: That's more or less where my current system sits, so it's the most practical one to target. We're building engine-level code rather than a game, so even if this gets widely adopted, there's a long lead time between \"now\" and when the first games will be available, and the the speed of game systems increases quickly. However, we'd like the system to scale to lower level hardware; we'd like at least 60fps on current generation Unity-capable consoles or Apple Silicon Macs, and ideally at least 30fps on late model Intel Macs and reasonably capable mobile devices (say, everything iOS and the \"top tenth\" of Android - basically flagship class devices, not the sub-$250 ones that make up the bulk of the Android world). World Size and Variety Ideally we'd like to be able to generate infinite worlds. As an initial goal, we'll aim for a generation of a one million square kilometer area (1000x1000 km) as the proof of concept. Our generated space should contain as high a variety of geomes as possible--at least sea, mountain, hills, plains, and riverbeds. We will include \"sea level\" water, but for the moment not worry about higher elevation, emitted, or moving water (any lakes or rivers will be \"dry\"), since Unity's support for such things is in flux right now. The world should be capable of having undercut erosion (i.e. overhangs and natural bridges) and cave systems of arbitrary complexity, but we'll assume that these systems are (to within an order of magnitude or so) similar in number to their real-world counterparts. That is, such features will be relatively rare; comprising a very small percentage of terrain space. Configurability The generation of worlds should allow the generator to control limits and biases. For example, there should be options to set the height of the highest mountains and the sea level, determine whether undersea features are present or not, determine the frequency of biomes/geomes in the world, and similar things. In addition, we'll want to allow the option to \"gamify\" the environment, things like: Number of caves increased, and caves made larger so as to be traversable by walking humans. A tendency for caves or spaces behind waterfalls An increase in (or even mandate for) natural \"switchbacks\" and \"collapsed slopes\" that allow access to most terrain without climbing or high-jumping mechanics (e.g that you can \"walk\" to most of the world, even mountain peaks and the like). Vertically spaced \"handholds\" for most steep surfaces (for games with climbing mechanics). More regions of increased verticality in general (canyons, badlands, cliffs, other eroded or uplifted spaces) An increase in \"dead end\" type terrains: places with few or even just one point of entry. For example: deep canyons, caulderas accessed through only one path or cave system, mountain valleys, etc. Region separation: natural boundaries that separate the world into mutually inaccessible (or difficult to access) regions. This allows the game to control player progression into \"higher level\" areas over time. Such boundaries will suppress the handholds/switchback options in the boundary areas. All of these should be able to be independently turned on or off; when they're all disabled, the worlds will tend toward the \"natural,\" independent of player accessibility.","title":"Requirements"},{"location":"Requirements/#requirements","text":"If the goal is to build something, it helps to know what we're trying to build. I've called this section \"Requirements,\" but this is an experimental project, so what we're listing here are really \"aspirational goals.\" Not all of these may be achievable, reasonable, or even technically possible. But we still want to describe what an \"ideal\" system would look like. For the moment, we're going to consider just Geology (that is, just the shape of the terrain, not what's on/in it.","title":"Requirements"},{"location":"Requirements/#target-software-platform","text":"Unity3D initially. Presumedly many of the concepts would move to other engines (particularly Unreal), but we're going to take advantage of whatever technologies Unity offers us without much concern for whether or not they're portable.","title":"Target Software Platform"},{"location":"Requirements/#scalability","text":"Our first requirement is that this system be scalable to different hardware. Our specific target is 90/90/90: 90 frames per second 90% of the time on 90th percentile gaming hardware (that is, a PC gaming system which can outperform 90 percent of all PC game systems.) Why exclude 90% of PCs? First, because the tail on systems is very long: See Steam's System Surveys here for samples. The bottom half or so of these systems aren't playing modern games much. But more importantly: That's more or less where my current system sits, so it's the most practical one to target. We're building engine-level code rather than a game, so even if this gets widely adopted, there's a long lead time between \"now\" and when the first games will be available, and the the speed of game systems increases quickly. However, we'd like the system to scale to lower level hardware; we'd like at least 60fps on current generation Unity-capable consoles or Apple Silicon Macs, and ideally at least 30fps on late model Intel Macs and reasonably capable mobile devices (say, everything iOS and the \"top tenth\" of Android - basically flagship class devices, not the sub-$250 ones that make up the bulk of the Android world).","title":"Scalability"},{"location":"Requirements/#world-size-and-variety","text":"Ideally we'd like to be able to generate infinite worlds. As an initial goal, we'll aim for a generation of a one million square kilometer area (1000x1000 km) as the proof of concept. Our generated space should contain as high a variety of geomes as possible--at least sea, mountain, hills, plains, and riverbeds. We will include \"sea level\" water, but for the moment not worry about higher elevation, emitted, or moving water (any lakes or rivers will be \"dry\"), since Unity's support for such things is in flux right now. The world should be capable of having undercut erosion (i.e. overhangs and natural bridges) and cave systems of arbitrary complexity, but we'll assume that these systems are (to within an order of magnitude or so) similar in number to their real-world counterparts. That is, such features will be relatively rare; comprising a very small percentage of terrain space.","title":"World Size and Variety"},{"location":"Requirements/#configurability","text":"The generation of worlds should allow the generator to control limits and biases. For example, there should be options to set the height of the highest mountains and the sea level, determine whether undersea features are present or not, determine the frequency of biomes/geomes in the world, and similar things. In addition, we'll want to allow the option to \"gamify\" the environment, things like: Number of caves increased, and caves made larger so as to be traversable by walking humans. A tendency for caves or spaces behind waterfalls An increase in (or even mandate for) natural \"switchbacks\" and \"collapsed slopes\" that allow access to most terrain without climbing or high-jumping mechanics (e.g that you can \"walk\" to most of the world, even mountain peaks and the like). Vertically spaced \"handholds\" for most steep surfaces (for games with climbing mechanics). More regions of increased verticality in general (canyons, badlands, cliffs, other eroded or uplifted spaces) An increase in \"dead end\" type terrains: places with few or even just one point of entry. For example: deep canyons, caulderas accessed through only one path or cave system, mountain valleys, etc. Region separation: natural boundaries that separate the world into mutually inaccessible (or difficult to access) regions. This allows the game to control player progression into \"higher level\" areas over time. Such boundaries will suppress the handholds/switchback options in the boundary areas. All of these should be able to be independently turned on or off; when they're all disabled, the worlds will tend toward the \"natural,\" independent of player accessibility.","title":"Configurability"},{"location":"_sidebar/","text":"Home Terrain Heightmaps Vs. Voxels Heightmaps Voxels Size of Game Worlds Geology Floating Point Precision Limits Level of Detail Requirements","title":" sidebar"},{"location":"heightmaps_and_voxels/","text":"Heightmaps vs. Voxels For our discussion, assume a three -dimensional, three axis coordinate space, with mutually orthogonal axes X, Y, and Z. The Y axis will represent height (i.e., it\u2019s the \u201cup and down\u201d axis), and X and Z represent horizontal positions. There are numerous different representations that meet these requirements (e.g., left-handed and right-handed coordinate systems); the specific one being used doesn\u2019t matter so long as consistency is maintained across the system (or accounted for: some of Unity\u2019s \u201cmap\u201d types invert the (X, Z) values from others). Heightmaps A \u201cheightmap\u201d is a two-dimensional array of height values (sometimes represented as a greyscale image where dark areas are \u2018low\u2019 and light areas are \u2018high\u2019) that describe the height of the geology at each (x, z) coordinate in space. This is a reasonably compact way of storing elevation/height values; is uniform in sampling; usually compresses well; and is extremely simple to implement, explain, and use. They also lend themselves well to machine generation; there are many simple and well-known algorithms for achieving natural-looking terrain with them. Heightmaps (aka \u201celevation maps\u201d) also exist for a wide variety of real-world scientific purposes where their overhang limitations are irrelevant, so there are a numerous sources that will let you \u201csample\u201d a portion of the real world to generate realistic looking (because it\u2019s actually real) locations for a game. The downside of heightmaps is that they represent only a single ground level per (x, z) location. This means they cannot be used to represent any structure that has multiple potential \u201cground\u201d surfaces at a single (x,z) point: most notably caves, but also bridges, tunnels, or even simple overhanging or undercut surfaces. (It also wouldn\u2019t represent building interiors, but human-constructed structures are almost always superimposed on the geology with game objects rather than being part of them, so this limitation usually doesn\u2019t matter). Whether or not this is a problem depends on the game. If the game does not require such structures, heightmaps are a good choice. Such games are numerous, and players often won\u2019t notice the absence of overhangs among all the other details of a good-looking world. It\u2019s also common to simply not model interior spaces as part of the terrain at all, and simply transition the player to a new scene representing the interior space (e.g., Skyrim ). If there are relatively few \u201coverhanging\u201d objects, they can be added to a heightmap-based world by using mesh game objects to create the overhanging parts, and adding them to the world like any other object. Conversely, recent versions of Unity allow heightmaps to define \u201choles\u201d in them, to which a custom mesh to represent, say, a cave interior can be \u201cattached.\u201d Both of these mechanisms are reasonably complex to implement, and while they could be automated, in practice usually require a trained modelling artist to design each instance. Less troublesome, but still a consideration is that the \u201cappended\u201d structure (the meshes that describe either the overhanging object or the cave) are different in nature from the terrain object itself, and need to be handled separately for things like collision, walkability, and navigation agent (or other AI) availability. This last point is especially important for games that implement player deformation of the terrain, usually in the form of digging. It\u2019s possible to limit the player to only single-height deformations (a standard \u201cbowl-shaped\u201d crater created by an explosion would be representable in a height map, for example). Even digging can be limited in this way, so long as digging always removes all terrain above the dug point. The recent (as of this writing) game Valheim does this reasonably successfully because of its generally shallow digging mechanism, but it does produce some odd behaviors on steep surfaces. For games where digging is a primary game element (e.g. the player may be removing large hunks of the world for building, resource gathering, area accessibility, or other purposes), the limitations of heightmaps can be considerable, as the player expects to be able to cut horizontal holes in vertical surfaces. Similarly, in games where the player can add to the surface, the inability to create overhangs will be immediately apparently. Voxels If a \u201cpixel\u201d is a two dimensional \u201cpixel element,\u201d a voxel is its three-dimensional counterpart: a \u201cvolume element.\u201d Voxel terrains involve representing the environment as a three-dimensional array of \u201cblocks\u201d, in which each block is either present or absent. This allows three dimensional structures that have as many potential \u201cground heights\u201d as they have blocks, and trivially represents things such as caves and overhangs. The canonical voxel world game is Minecraft . The Minecraft world is made up of cubical blocks about half the height of the player, and effectively any block can be removed or replaced to solve the game\u2019s puzzles and build whatever the player wishes. Compared to what we think of as pixels, Minecraft\u2019s voxels are very, very large. That\u2019s typical of voxel based games, because representing any significant amount of terrain with sub-millimeter sized voxels would require prohibitively large amounts of memory. In the block-based world of Minecraft, the large block sizes are a design benefit; much of the game\u2019s distinctive style and \u201cfeel\u201d comes from its blocky nature. If we wish to represent more natural-looking voxel terrain, there are obstacles that need to be overcome. The most obvious one is the blocky nature of the terrain. Since the voxel \u201cblocks\u201d need to be converted to a mesh for display anyway, we can use this conversion as an opportunity to \u2018smooth\u2019 the blocks into something less chunky. There are well-known methods to do this, in particular the marching cubes or marching tetrahedrons algorithms. These generate meshes more complex than the pure cubes of the underlying voxel representation, but they\u2019re relatively inexpensive to implement because they\u2019re primarily lookup-table based. At a very high level, each vertex and face of a block is replaced by a new face based on the present/not present state of the bock itself and the neighboring blocks in the direction of the vertex or face. When flat shaded, the resulting terrains would still not be mistaken for entirely natural. Again, this could be an advantage: System Era Softworks\u2019s Astroneer uses this sort of \u201csmoothed voxel\u201d terrain as a stylistic choice; it perfectly matches the cartoony, low-polygon aesthetic of the rest of the game\u2019s elements. More sophisticated shading and texturing algorithms can mask the polygonization of the terrain and make it appear realistic. A bigger problem is memory, or its related sibling, resolution. A default size terrain in Unity has 512 edges in each direction, for a heightmap (which records vertex heights, not planar heights) of 513x513 heights. Assuming each height element is a 32-bit float, the heightmap can be represented in a little over 8MB of memory. Not tiny by any stretch, but quite manageable for any modern computer. The mesh generated from that heightmap will be larger: each vertex of the resulting mesh having a position in 3D space, it\u2019s going to be a minimum of about 24MB, and probably more once you include texture UV\u2019s, normal maps, and all the other aesthetic niceties of the modern rendering engine. But even if it approaches 100MB, that represents (at the commonly used scale of one Unity unit per \u201creal world\u201d meter) about a quarter of a square kilometer of space for the player to move around in; extending that to vision distances of maybe a couple kilometers square would still fit comfortably in two or three gigabytes of memory; even less with level of detail and mipmap optimizations. So what about the voxel world? If we assume our voxels are one Unity unit on an edge, we need 512 x 512 x N of them, where N is the \u201cheight range\u201d of the terrain: the distance between the lowest and highest. Since typical implementations use a square grid, if we assume a 512 block height range, we get about 135 million blocks. If our terrain consists of a single bit of memory for each block (present or not present), that\u2019s about 16MB of data for the voxel representation. Each block when converted to a mesh will have as many as 8 vertices using the blocky Minecraft representation, or up to about 16 using the marching cubes implementation. At 3x32 bits for each of those, we\u2019re up to more than 1.5 gigabytes just for the basic mesh, and again some multiple of that for the other miscellanea. That\u2019s a na\u00efve implementation\u2014most or all of those vertices are shared with other blocks, and the majority of vertices won\u2019t be present at all in non-pathological terrains because they\u2019re inside solid areas or in the \u201cair\u201d and omitted altogether. Ultimately, a voxel-based representation of the same terrain that\u2019s produced from a heightmap will generate identical or near-identical meshes, albeit without taking advantage of any of the voxel\u2019s overhang advantages. But achieving these niceties takes computing time. At a very high level, the fundamental takeaway is this: despite their three-dimensional appearance, heightmaps are fundamentally a two-dimensional \u201cspace\u201d (they represent a single, non-overlapping surface), and voxel terrains are fundamentally a three-dimensional one. And the number of dimensions maps directly to the amount of computation for things like mesh generation, texturing, rendering, storage, etc. When we get down to grinding code; heightmap computations (for \u201cwhatever\u201d) tend to be a set of nested for loops: For x in 0\u2026xsize For z in 0\u2026zsize {\u2026} Voxel implementations, on the other hand, tend to be nested three levels deep: For x in 0\u2026xsize For y in 0\u2026ysize For z in 0\u2026zsize {\u2026} This extra dimension buys us the advantages of a true three-dimensional representation, but at a significant computational cost (effectively a multiplier by the size of the extra dimension). There are a lot of ways to reduce the cost of voxel terrain operations. Since the process tends to be of the \u201cdo some relatively simple thing on all these positions\u201d type, large gains can be achieved on modern systems by moving some of the work to the GPU via various shaders. But even after optimizations and across a wide range of algorithms, the extra dimension multiplier remains. For that reason, voxel worlds tend to be generated and rendered in relatively small \u201cchunks.\u201d While a Unity terrain object can easily handle a square 512 Unity units on an edge (and on beefy hardware, 4K x 4x or larger terrain objects), a 512 x 512 x 512 voxel cube would bring even a high-end 2021-era CPU to its knees. More typical sizes are 16x16x16 (or if on GPU, 32x32x32) chunks, several of which are generated and placed next to each other to build the terrain. The total number of chunks is then adjusted to computational capability of the hardware. A reference Unity implementation (largely unoptimized, and not using compute shaders) I use can generate roughly a 5x5 set of chunks in realtime at decent frame rates on a midrange Intel Macintosh, or about a 7x7 set of chunks on a high end gaming PC. Many versions of Minecraft allow you to set the number of rendered chunks in the settings, as well, to play around with what numbers a decent implementation can provide. This breakdown into chunks provides an additional benefit. For most circumstances, most of the time, a player avatar standing on the surface of a 512x512x512 chunk wouldn\u2019t be able to see the vast majority of the voxels, anyway \u2013 they\u2019d be \u201cunderground.\u201d There\u2019s also no point in rendering large numbers of voxels that are all \u201cair.\u201d The breakdown into smaller chunks means that we\u2019re rendering only the voxels that are near the surface of the terrain (or just the ones in the player\u2019s vicinity, if they\u2019re underground). This could result in the player being able to see a full 512x512 (or greater) terrain space, not realizing that they\u2019re standing on a thin \u201cshell\u201d only one or two chunks thick. We only need to render the deeper chunks when at least one voxel in them becomes visible. Is that enough? It depends on the game world, environment, and the complexity of the rest of the terrain generation. This is where we need to start talking about size.","title":"Heightmaps or Voxels"},{"location":"heightmaps_and_voxels/#heightmaps-vs-voxels","text":"For our discussion, assume a three -dimensional, three axis coordinate space, with mutually orthogonal axes X, Y, and Z. The Y axis will represent height (i.e., it\u2019s the \u201cup and down\u201d axis), and X and Z represent horizontal positions. There are numerous different representations that meet these requirements (e.g., left-handed and right-handed coordinate systems); the specific one being used doesn\u2019t matter so long as consistency is maintained across the system (or accounted for: some of Unity\u2019s \u201cmap\u201d types invert the (X, Z) values from others).","title":"Heightmaps vs. Voxels"},{"location":"heightmaps_and_voxels/#heightmaps","text":"A \u201cheightmap\u201d is a two-dimensional array of height values (sometimes represented as a greyscale image where dark areas are \u2018low\u2019 and light areas are \u2018high\u2019) that describe the height of the geology at each (x, z) coordinate in space. This is a reasonably compact way of storing elevation/height values; is uniform in sampling; usually compresses well; and is extremely simple to implement, explain, and use. They also lend themselves well to machine generation; there are many simple and well-known algorithms for achieving natural-looking terrain with them. Heightmaps (aka \u201celevation maps\u201d) also exist for a wide variety of real-world scientific purposes where their overhang limitations are irrelevant, so there are a numerous sources that will let you \u201csample\u201d a portion of the real world to generate realistic looking (because it\u2019s actually real) locations for a game. The downside of heightmaps is that they represent only a single ground level per (x, z) location. This means they cannot be used to represent any structure that has multiple potential \u201cground\u201d surfaces at a single (x,z) point: most notably caves, but also bridges, tunnels, or even simple overhanging or undercut surfaces. (It also wouldn\u2019t represent building interiors, but human-constructed structures are almost always superimposed on the geology with game objects rather than being part of them, so this limitation usually doesn\u2019t matter). Whether or not this is a problem depends on the game. If the game does not require such structures, heightmaps are a good choice. Such games are numerous, and players often won\u2019t notice the absence of overhangs among all the other details of a good-looking world. It\u2019s also common to simply not model interior spaces as part of the terrain at all, and simply transition the player to a new scene representing the interior space (e.g., Skyrim ). If there are relatively few \u201coverhanging\u201d objects, they can be added to a heightmap-based world by using mesh game objects to create the overhanging parts, and adding them to the world like any other object. Conversely, recent versions of Unity allow heightmaps to define \u201choles\u201d in them, to which a custom mesh to represent, say, a cave interior can be \u201cattached.\u201d Both of these mechanisms are reasonably complex to implement, and while they could be automated, in practice usually require a trained modelling artist to design each instance. Less troublesome, but still a consideration is that the \u201cappended\u201d structure (the meshes that describe either the overhanging object or the cave) are different in nature from the terrain object itself, and need to be handled separately for things like collision, walkability, and navigation agent (or other AI) availability. This last point is especially important for games that implement player deformation of the terrain, usually in the form of digging. It\u2019s possible to limit the player to only single-height deformations (a standard \u201cbowl-shaped\u201d crater created by an explosion would be representable in a height map, for example). Even digging can be limited in this way, so long as digging always removes all terrain above the dug point. The recent (as of this writing) game Valheim does this reasonably successfully because of its generally shallow digging mechanism, but it does produce some odd behaviors on steep surfaces. For games where digging is a primary game element (e.g. the player may be removing large hunks of the world for building, resource gathering, area accessibility, or other purposes), the limitations of heightmaps can be considerable, as the player expects to be able to cut horizontal holes in vertical surfaces. Similarly, in games where the player can add to the surface, the inability to create overhangs will be immediately apparently.","title":"Heightmaps"},{"location":"heightmaps_and_voxels/#voxels","text":"If a \u201cpixel\u201d is a two dimensional \u201cpixel element,\u201d a voxel is its three-dimensional counterpart: a \u201cvolume element.\u201d Voxel terrains involve representing the environment as a three-dimensional array of \u201cblocks\u201d, in which each block is either present or absent. This allows three dimensional structures that have as many potential \u201cground heights\u201d as they have blocks, and trivially represents things such as caves and overhangs. The canonical voxel world game is Minecraft . The Minecraft world is made up of cubical blocks about half the height of the player, and effectively any block can be removed or replaced to solve the game\u2019s puzzles and build whatever the player wishes. Compared to what we think of as pixels, Minecraft\u2019s voxels are very, very large. That\u2019s typical of voxel based games, because representing any significant amount of terrain with sub-millimeter sized voxels would require prohibitively large amounts of memory. In the block-based world of Minecraft, the large block sizes are a design benefit; much of the game\u2019s distinctive style and \u201cfeel\u201d comes from its blocky nature. If we wish to represent more natural-looking voxel terrain, there are obstacles that need to be overcome. The most obvious one is the blocky nature of the terrain. Since the voxel \u201cblocks\u201d need to be converted to a mesh for display anyway, we can use this conversion as an opportunity to \u2018smooth\u2019 the blocks into something less chunky. There are well-known methods to do this, in particular the marching cubes or marching tetrahedrons algorithms. These generate meshes more complex than the pure cubes of the underlying voxel representation, but they\u2019re relatively inexpensive to implement because they\u2019re primarily lookup-table based. At a very high level, each vertex and face of a block is replaced by a new face based on the present/not present state of the bock itself and the neighboring blocks in the direction of the vertex or face. When flat shaded, the resulting terrains would still not be mistaken for entirely natural. Again, this could be an advantage: System Era Softworks\u2019s Astroneer uses this sort of \u201csmoothed voxel\u201d terrain as a stylistic choice; it perfectly matches the cartoony, low-polygon aesthetic of the rest of the game\u2019s elements. More sophisticated shading and texturing algorithms can mask the polygonization of the terrain and make it appear realistic. A bigger problem is memory, or its related sibling, resolution. A default size terrain in Unity has 512 edges in each direction, for a heightmap (which records vertex heights, not planar heights) of 513x513 heights. Assuming each height element is a 32-bit float, the heightmap can be represented in a little over 8MB of memory. Not tiny by any stretch, but quite manageable for any modern computer. The mesh generated from that heightmap will be larger: each vertex of the resulting mesh having a position in 3D space, it\u2019s going to be a minimum of about 24MB, and probably more once you include texture UV\u2019s, normal maps, and all the other aesthetic niceties of the modern rendering engine. But even if it approaches 100MB, that represents (at the commonly used scale of one Unity unit per \u201creal world\u201d meter) about a quarter of a square kilometer of space for the player to move around in; extending that to vision distances of maybe a couple kilometers square would still fit comfortably in two or three gigabytes of memory; even less with level of detail and mipmap optimizations. So what about the voxel world? If we assume our voxels are one Unity unit on an edge, we need 512 x 512 x N of them, where N is the \u201cheight range\u201d of the terrain: the distance between the lowest and highest. Since typical implementations use a square grid, if we assume a 512 block height range, we get about 135 million blocks. If our terrain consists of a single bit of memory for each block (present or not present), that\u2019s about 16MB of data for the voxel representation. Each block when converted to a mesh will have as many as 8 vertices using the blocky Minecraft representation, or up to about 16 using the marching cubes implementation. At 3x32 bits for each of those, we\u2019re up to more than 1.5 gigabytes just for the basic mesh, and again some multiple of that for the other miscellanea. That\u2019s a na\u00efve implementation\u2014most or all of those vertices are shared with other blocks, and the majority of vertices won\u2019t be present at all in non-pathological terrains because they\u2019re inside solid areas or in the \u201cair\u201d and omitted altogether. Ultimately, a voxel-based representation of the same terrain that\u2019s produced from a heightmap will generate identical or near-identical meshes, albeit without taking advantage of any of the voxel\u2019s overhang advantages. But achieving these niceties takes computing time. At a very high level, the fundamental takeaway is this: despite their three-dimensional appearance, heightmaps are fundamentally a two-dimensional \u201cspace\u201d (they represent a single, non-overlapping surface), and voxel terrains are fundamentally a three-dimensional one. And the number of dimensions maps directly to the amount of computation for things like mesh generation, texturing, rendering, storage, etc. When we get down to grinding code; heightmap computations (for \u201cwhatever\u201d) tend to be a set of nested for loops: For x in 0\u2026xsize For z in 0\u2026zsize {\u2026} Voxel implementations, on the other hand, tend to be nested three levels deep: For x in 0\u2026xsize For y in 0\u2026ysize For z in 0\u2026zsize {\u2026} This extra dimension buys us the advantages of a true three-dimensional representation, but at a significant computational cost (effectively a multiplier by the size of the extra dimension). There are a lot of ways to reduce the cost of voxel terrain operations. Since the process tends to be of the \u201cdo some relatively simple thing on all these positions\u201d type, large gains can be achieved on modern systems by moving some of the work to the GPU via various shaders. But even after optimizations and across a wide range of algorithms, the extra dimension multiplier remains. For that reason, voxel worlds tend to be generated and rendered in relatively small \u201cchunks.\u201d While a Unity terrain object can easily handle a square 512 Unity units on an edge (and on beefy hardware, 4K x 4x or larger terrain objects), a 512 x 512 x 512 voxel cube would bring even a high-end 2021-era CPU to its knees. More typical sizes are 16x16x16 (or if on GPU, 32x32x32) chunks, several of which are generated and placed next to each other to build the terrain. The total number of chunks is then adjusted to computational capability of the hardware. A reference Unity implementation (largely unoptimized, and not using compute shaders) I use can generate roughly a 5x5 set of chunks in realtime at decent frame rates on a midrange Intel Macintosh, or about a 7x7 set of chunks on a high end gaming PC. Many versions of Minecraft allow you to set the number of rendered chunks in the settings, as well, to play around with what numbers a decent implementation can provide. This breakdown into chunks provides an additional benefit. For most circumstances, most of the time, a player avatar standing on the surface of a 512x512x512 chunk wouldn\u2019t be able to see the vast majority of the voxels, anyway \u2013 they\u2019d be \u201cunderground.\u201d There\u2019s also no point in rendering large numbers of voxels that are all \u201cair.\u201d The breakdown into smaller chunks means that we\u2019re rendering only the voxels that are near the surface of the terrain (or just the ones in the player\u2019s vicinity, if they\u2019re underground). This could result in the player being able to see a full 512x512 (or greater) terrain space, not realizing that they\u2019re standing on a thin \u201cshell\u201d only one or two chunks thick. We only need to render the deeper chunks when at least one voxel in them becomes visible. Is that enough? It depends on the game world, environment, and the complexity of the rest of the terrain generation. This is where we need to start talking about size.","title":"Voxels"},{"location":"size_of_game_worlds/","text":"Size of Game Worlds By and large, game worlds are tiny. Very, very tiny. This includes the \u201chuge open worlds\u201d that have become popular. We have become accustomed to the metaphors of game environments to the point where we often don\u2019t consciously notice the weird sizes of things. Let\u2019s assume human player characters are of standard human size, that is, somewhere between 1.5 and 2 meters in height. Normal human walking speeds are in the vicinity of 3-5 km/hour, maybe twice that at the \u201cfast jog\u201d that seems to be most game characters\u2019 primary locomotion. From these, along with timing how long it takes to make various journeys in the game world, we can get rough estimates of the sizes that these worlds and objects would be if \u201csuperimposed\u201d on the real world. The numbers are surprisingly small. You could fit all of World of Warcraft\u2019s Azeroth, along with all the lands of its various expansions, several times into the county I live in\u2014it is variously estimated online at being between 200-800 square miles. A knowledgeable player could cross the original continent of Everquest\u2019s Norrath on foot in about 40 minutes. (Spoiler: it takes a little longer than that to cross real continents on foot. Try it!) Those huge, craggy, massive mountains that blot out the sky of Skyrim? The tallest is about 700 meters\u2014certainly big enough that it might be called a mountain rather than a hill (especially with that craggy shape), but nowhere near the size you\u2019d expect for its prominence in the skyline. The entire world of Skyrim covers less than 15 square miles, smaller than my town. For comparison: the base of Mt. Hood\u2014a single, moderately large volcano in Oregon\u2014covers more than 92 square miles. Whole planets in No Man\u2019s Sky are somewhere in the vicinity of twenty miles in diameter (although there are quintillions of them, so the total land area is\u2026big.) Ignoring infinite and/or near-infinite procedurally generated terrains and real-world sampled ones, I\u2019d estimate that all of the artist-designed game worlds in all computer games ever written put together would fit comfortably inside of Texas, with room left over for a lot of rattlesnakes. Things get even weirder when we consider population centers and commerce: a bustling metropolis in most of these games would have fewer than 100 residents; it\u2019s not uncommon for there to be a fully-stocked store that could literally outfit an army of adventurers in a town of eight people (and for some reason, a frighteningly large number of these shopkeepers need rats removed from their cellars). There are reasons for all these numbers, of course. The primary one, of course, is that even granting very fast travel, the vast majority of an \u201cEarth-sized world\u201d would never be seen by players. Games also have limits on how large they can be, even in an era of multi-terrabyte storage. Artists are expensive, and designing large spaces that are unlikely to be seen isn\u2019t a financially productive use of their time. Players would likely be bored if they had to spend real-world amounts of time traversing between towns or navigating about a city. For games, a better metric of world size is probably something like \u201cinterest density;\u201d some sort of measure of how many distinct places there are to visit or things to do in the game world. You can see this in city racing games: there\u2019s a lot of physical space, but it\u2019s not very detailed (almost no buildings would have interiors, for example) because the players will be literally racing by it at high speeds most of the time. On the other side, Skyrim has hundreds of points of interest and biomes scattered around it\u2019s very small (by real world standards) land area. The environment is vastly denser than the real world, giving players much less \u201ctravel time\u201d for their adventures while still creating a psychologically large sense of scale. Of course, games aren\u2019t the only uses for terrains, and for simulation purposes, real-world-analog sizes and distances are important. Microsoft Flight Simulator models, in essence, the entire (real) Earth by way of streamed geologic data. Google Earth similarly presents Earth itself in its full-scale glory. We have renderable terrain data for Mars and the Moon, as well. In some applications, there\u2019s value in being able to generate \u201creal world-like\u201d terrains at will (often enhancing or emphasizing some geologic attributes for things like pilot training in mountainous areas or spacecraft landing in unexplored terrains.) All this boils down to: it would be useful to be able to create both \u201cfull scale\u201d and \u201ccompressed\u201d terrains in order to maximize the applicability of our terrain generation engine. Geology We\u2019ll start with geology. As mentioned earlier, many games combine the notion of the physical shape of the land with the biological and other \u2018things\u2019 that grow or sit upon it, referring to the entire combination as a biome. For example, the Minecraft desert biome is always made up of shallow, gentle hills (reminiscent of dunes), the mountain biome is steep and (even by Minecraft standards) jagged, swamps are almost entirely flat, and so on. While these describe real-world scenarios well enough that they don\u2019t seem unnatural (at least in a world made entirely of cubes), they discount a number of possibilities. Not all mountains, jungles, hills, or forests are the same, and in many cases a single geographical entity might have many biological environments represented in it (mountains and hills, in particular, cross multiple elevations, and even with something like deserts there\u2019s amazing variablility). Still, it\u2019s handy to have a term for a particular geologic \u201cshape,\u201d so we\u2019ll call this a geome. A geome is a description of physical shape (e.g. mountainous, hilly, flat, etc.) without regard to the life or other decoration that appears on it. There are a number of mathematical mechanisms that we can use to generate natural-looking geological structures, most of them fractal in nature--that is, if we \u201czoom in\u201d on a particular sub-region of a geome, the types of shapes we see will be similar to the shape of the whole geome in structure, jaggedness, height variability, and so on. For example, \u201csmooth\u201d old mountains tend to be fairly smooth at every scale due to long-term erosion; \u201cyoung\u201d mountains tend to be sharper and rougher at both the large and the small scale. The rippling shapes of sand on desert dunes is often reminiscent of the shape of the dunes themselves. Real world fractals can maintain this self-similarity over very large ranges of size, but our synthetic ones stop at whatever the \u201cresolution\u201d of the world is on the small end (e.g. for Minecraft, the fractal nature ends at each cube. For a marching cubes/tetrahedrons implementation, it would break down each \u201ccube\u201d one more time into polygons, which would then be flat and not broken down further.) On the larger end, the structure stops at the point of the largest element of the geography: a mountain, a hill, a plain, an ocean, or whatever, although you could extend the model to whole continents or planets (and once you get planets, you\u2019ve got self similarity on huge scales again: moons orbiting planets orbiting stars orbiting galaxies orbiting clusters\u2026). Ignoring water, mountains and other large structures are the hardest part of generating terrains simply because they\u2019re large. This is particularly true for voxel terrains, because a single mountain (even a game-scale one, and definitely real-scale ones) would consist of far more 16-32 meter voxel chunks than are ever likely to be loaded at once. But even the simpler terrain objects have trouble representing spaces that are larger than a kilometer or so in a given direction. Solutions fall into several categories. The simplest is just not to allow such large terrains: even a lot of \u201copen world\u201d games have maps that cover very small amounts of actual space, usually by increasing the detail density to a level that you would never see in the real world, but that meets our expectations in games. For artist-generated worlds, the artist can combine multiple terrain or voxel objects; build the terrain as a monolithic whole, then separate them again for streaming at play time. Floating Point Precision Limits There is, as always, another problem. Coordinates in Unity (and for that matter most game engines and video cards) are stored as standard 32-bit floating point numbers. The \u201cfloating\u201d of \u201cfloating point numbers\u201d means that the decimal point can move around in the number--but the total number of bits is fixed. Which, in turn, means that there are only so many bits to go around: the larger the integer portion, the fewer bits are available to represent the decimal portion of the numbers. So, it\u2019s an inherent property of floating point numbers that the larger the absolute number, the lower the decimal precision. For most numerical uses, that\u2019s fine\u2014even desirable. We generally care about precision as a number of significant digits, and we tend to \u201cround\u201d large numbers more than small ones, anyway. If you are doing math on large numbers, the rightmost decimal digits are likely noise or uncertain, anyway. But when we\u2019re using these numbers to generate positions for things: trees, rocks, animals, mountains\u2026that lack of decimal precision is problematic. As our virtual character wanders farther and farther from the origin of their world, the \u201cgrid\u201d size on which things can be placed becomes coarser and coarser. This is because while we\u2019re considering the character\u2019s position on some global grid, the character\u2019s interest is always local--concerning the objects that are positioned around them. Unity doesn\u2019t enforce any particular interpretation of its units, but common convention sets one Unity Unit to one real-world meter (e.g. an approximately human character is between 1 and 2 Unity Units high in most game engines). A 32-bit floating point value has roughly 7 (decimal) digits of precision. So, if we\u2019re representing a position in meters, and we want at least centimeter (1/100 meter) resolution, we need to reserve two of those digits for decimal places. That leaves us about 5 decimal places of potential distance, or about 10,000 meters in which we can position things with centimeter accuracy. Since the coordinate systems are usually centered on the origin, that means our character can move (or see) about five in-game kilometers from the origin before the precision with which we can place objects drops to a tenth of a meter instead of a hundredth. Beyond 50 kilometers, we can\u2019t even place objects a meter apart reliably, and it gets worse from there. How the game engine deals with this falloff of precision after 5000 meters or so depends on the engine, but most of them will have objects \u201cjumping\u201d or \u201cshaking\u201d when placed with higher accuracy than the coordinate position allows, and certainly if you\u2019re allowing travel beyond 20 kilometers or so the errors will be too large to ignore even if you\u2019re willing to tolerate the jitter. For objects with small details, the problems get worse: render pipelines will often include steps where the model\u2019s \u201cobject\u201d coordinates are translated into \u201cworld\u201d coordinates. In such scenarios, the individual vertices of the model will be subject to the precision limits of that part of the world, and serious (and very visible) distortion will result. The financial industry has been dealing with this for decades, and their solution is usually to not use floating point numbers at all to represent currency, but rather a (large) integer number of the smallest currency unit (in the US, pennies, maybe) that needs to be represented. That doesn\u2019t help us come actual render time, because we don\u2019t have control over Unity\u2019s coordinate implementation. But we can borrow this mechanism for actually positioning things in our \u2018world\u2019 for long-term storage or generation: We can calculate positions using (say) 64-bit integer numbers of centimeters, which gives us a \u201cresolution\u201d of several quadrillion meters before we run out of space\u2014enough to represent the entire surface of any planet in our solar system to centimeter accuracy. Double-precision floats can give you trillions of meters at centimeter accuracy. Need more? Most platforms give you access to 128-bit integers, as well, which can safely be described as \u201ceffectively infinite\u201d for this purpose. If your platform provides quadruple-precision floating point numbers, you could use these, too. The \u201cinteger number of some fraction\u201d is effectively the same idea as fixed-point numbers, also provided by some libraries in large forms. Once we need to push polygons to screen, though, we\u2019re going to have to live with the limitations of 32-bit floating point numbers. And that means we need to keep moving the origin so that it stays near the player. This implies a degree of chunking even to non-voxel worlds (in the voxel case, the chunks are handily already provided!). When a certain distance is reached, the player and every \u201cnearby\u201d object will be translated or reloaded relative to a new origin point closer to the player. Finally, consider a character standing on a mountaintop on a clear day. On Earth, that character would be able to see perhaps a hundred kilometers in any direction. This seems to throw a wrench into our \u201ceverything has to be within 5000 meters of the player\u201d rule. There are all sorts of reasons why this scenario is hard, not the least of which is that there\u2019s an awful lot of \u201cthere\u201d there. But once we observe that the character isn\u2019t going to be seeing centimeter-sized details from 5km away, nor meter-sized ones at 100km, it becomes a little easier. We\u2019re going to have to solve level-of-detail (LOD) issues, anyway, so we just need to be aware that floating-point precision is going to put an upper bound on how precise each detail level can be--probably a weaker bound than the actual amount of space, though. If the world is divided into 1km square terrain pieces, our mountaintop viewer can see potentially a hundred thousand of them at once, which means each one can\u2019t have many polygons, anyway. Level of Detail ...and that brings up the next point. It's fairly common to have terrain rendered on top of an (x,z) mesh where the vertices are one meter apart. Unity uses \"unity units\", which have no explicit size out of context, but by common convention many modelers base it on a 1UU = 1M scale, so a typical human is somewhere between one and two units in height, depending on age, gender, physique, etc. The continental United States is approximately 4500 x 2500 kilometers, so it would have something over eleven trillion \"vertices\" if measured on a coordinate grid. Of course, at that scale the curvature of the Earth would make a mess of pure cartesian coordinates, but in many applications\u2014even some real world ones\u2014that can be ignored. Real world map data at that scale does exist, for example see the USDA Geospatial Data Gateway for LiDAR maps of most of the United States at one meter resolution. But these data sets are very large: even if you could somehow represent each height element as a single byte, that's over eleven terabytes for the U.S. alone. Technical discussions always run the risk of rapidly becoming outdated by the march of technological progress, but at least in mid-2021, it's reasonable to say that no video card is going to push 11 terabytes of coordinate data (nor the 22 trillion resulting tesselated polygons) at all, much less in real time. And never mind the GPU: very, very few modern computers are likely sporting 11 TB of RAM, and while a few folks may have that level of secondary storage, they're going to be in a distinct minority, as well. So there are compromises to be made, depending on the applicaton. Reduce the data set As a starting point, consider whether we need to store that much data at all. Flight simulators, and other scenarios where the player isn't going to get a good look at terrain details can probably get by with much less than 1m resolution. If you can reduce your grid to, say, ten meter spacing, your 11 TB dataset is now a mere few hundred GB, and if you can use hundred meter spacing, you're within the sizes acceptable for a downloadable game these days. Alternatively, even in a flight simulator, the player isn't going to be able to see most of the US at any given moment--or for most flights, at all. Streaming just the needed data from a large cloud source might work, especially in combination with level of detail calculations. For example, your game might need 1m resolution near airports, but only 10m resolution for most of a flight where the plane is at 30,000 feet altitude. Similarly, GPS mapping systems meant for automobile navigation need basically no data at all for areas not on a roadway. Even better, roads have relatively few configurations in the real world, so a hundred miles of interstate through the central plains might take only a few hundred bytes of data to accurately represent. A curving mountain road or logging road might require a much higher information density, but they make up a relatively small percentage of the total roads. For game worlds that don't represent real worlds, we have additional options. There are numerous mechanisms for generating \"random\" terrains from seed values, or for using seed values to 'search' into some mathematical space, such as Perlin noise. In both cases, the seed values can be generated hierarchically from a higher level seed. For example, use one seed integer for the world, use that to generate the seed values for quarters of the world, subdivide each of those into quarters using those seeds, and so on, in a space partitioning algorithm. Since this generates a binary (really quadrary) tree, the \"deepest\" seeds can be generated from the initial seed in a logarithmic number of steps; a few dozen iterations will get us to US-sized spaces with ease. Even easier is to skit the seed generation (or use only one \"world\" seed) and just use the coordinates of the desired location as the \"seed\" or lookup key. Minecraft does this, using the world coordinates to look up a position in a Perlin (or similar) continuous 3D noise function to generate its terrain. Non-voxel games, or games in which 3D overhangs do not appear, can use a simpler 2D noise function. If the player cannot modify the world, using these generation methods means that no terrain data need be stored at all; it can always be regenerated (and on modern systems, possibly even done on the GPU itself via shader) based on the player's (or some other entity's) position. If player interations are limited to surface elements (chopping down trees, picking up rocks, killing monsters, etc.), only the \"things\" in the world need to be stored long term. Even if the player can modify the world's terrain itself (digging, building, blasting, whatever), it is unlikely that the vast majority of \"chunks\" in the world will remain forever untouched by the player, and only those chunks that are modified need to be stored. It's not uncommon for even that storage to be time- or space-limited; returning to a modified terrain after a long absence (or after modifying lots of other terrain in the interim) will in some games result in the player's modifications being lost: the game trades off the likelyhood that the player will return to a long-ago-important location against limiting the size of the \"modified chunks\" cache. (I'm suddenly envisioning a hypothetical game in which players smash asteroids into planets from space, thus violating the \"players only modify things really near themselves\" rule, but that'll take a different design entirely.) Reduce the Level of Detail Somewhat orthogonal to the question of how much data is being used to store the world, is the question of how much data is being used to store the parts of it that the player can actually see at any given moment. The answer might be \"all of it;\" Astroneer , No Man's Sky and Empyrion all feature gameplay elements where a player approaches a planet from space, and at least during these ascent/descent sequences can see a significant fraction of the entire surface of the planet. All of them make visibly obvious simplifications to the world in order to pull it off. Most notably, terrain \"snaps\" into more and more detailed configurations as the player approaches the surface, and \"ground\" clutter things like trees, plants, objects, and animals either do not appear at all until landing, or only when the player is extremely close to the ground. ( No Man's Sky uses the same \"hide the details\" mechanism even for relatively low flight, unless the player's spacecraft moves extremely slowly with respect to the terrain.) More typically, the player is on the ground, and their vision will be limited by any nearby objects, the terrain itself, the horizon (real or virtual), and other factors. Video games often supplement this with fog or other visibility-limiting elements, but we're interested here in the \"clear day\" scenarios. The Internet\u2014which would never lie to me\u2014tells me that the horizon as viewed from a height h above the ground on a flat plain or ocean, will be a distance d away based on: $$ d = 10000 * \\sqrt{h / 6.752} $$ Where d and h are in centimeters. (Drop the 10K multiplier to get d in kilometers, since it will typically be large). For an average height human standing up, that's going to be a little less than 5km (or 3 miles, but games almost always use metric internally). Which isn't too bad. A circle with that radius has about 78 million square meters, most of which will be out of sight behind or to the side of the player. It's still too much to draw: If we can \"see\" 25 million of them, and they have two polygons each, that's about 4.5 billion polygons we'll need to draw per second to get 90 fps. A fairly high end modern video card can do that under optimal circumsances, but it doesn't leave us much polygon budget for the rest of the game, nor any real support for more typical hardware. It's also (probably coincidentally) just about the range at which floating point errors will start being visible. And that's a best case. Add even a few dozen centimeters (say, a character jumping), and you'll get a few hundred meters of additional view. Let the character be standing on a mountainside at 3000 meters, and they'll be able to see more than 200 kilometers. That's reversable, too; a player on a flat plain will be able to see at least part of a 3000 meter mountain even if it's 200 km away from them. Even that's hardly a worst case. Earth's Mt. Everest is almost three times that high, even the old and eroded Cascade Mountains in the US Pacific Northwest have several volcanos well over the 3000 meter mark. Lower-gravity worlds are likely to have features many times larger still. As we discussed above, though, the primary problem here are those 1m resolution polygons. At the opposite end of the equation, I could represent the entire United States (badly) with a single polygon. It wouldn't capture most of the details, but with a reasonable texture on it, and viewed from, say, the moon or high orbit, it might work fine. The \"Secret Sauce,\" of course, is to mix the levels. Things nearby the player should be modelled at higher resolutions, things further away can be modelled at progressively lower resolutions the farther away they are. It would probably be possible to build a continuous version of this (where every polygon has it's vertex resolution determined by how far it is from the player), but more generally LOD systems tend to be zoned. For example, terrain within a kilometer of the player is at 1meter resolution, then 2 meter resolution for another kilometer, 16 meter resolution for another few kilometers, and 128 meter resolution beyond that (these numbers are made up for example and will be highly dependent on the particular engine and game.) Zones will usually \"round\" to chunks of some sort. For example, if we're using Unity Terrain objects with 512x512 meter edges, it would be reasonable to have the Terrain in which the character is located be at 1meter resolution, as well as the nine or twenty-four Terrains encircling that one. Beyond that, the Terrain objects may be built at lower resolutions (and possibly higher sizes) out to whatever maximum visibility we allow. As the player moves and leaves their current Terrain, the ones that are now \"too far\" from the player are discarded in favor of lower-resolution versions, and new ones that have come \"in range\" are generated or re-generated at higher resolution. Note : Unity terrains have an internal level of detail that describes their shapes using a minimum set of polygons: rough areas have more polygons than smooth ones (which discard vertices which would just be in a plane described by the surrounding ones). This is done automatically and internally as the shapes of the terrain change, and scales with the scale of the terrain. So we get this extra optimization \"for free,\" at least until our terrains become too complex. We may be able to apply additional optimizations: If the game does not allow a player to move underwater, it's reasonable to simplify \"undersea\" terrain significantly, since the player will never see it. A very sophisticated engine might be able to determine that large amounts of terrain are \"over the hill,\" occluded by a mountain, or otherwise blocked by the existing terrain from the player's view point, and not generate that space at all until needed.","title":"Size"},{"location":"size_of_game_worlds/#size-of-game-worlds","text":"By and large, game worlds are tiny. Very, very tiny. This includes the \u201chuge open worlds\u201d that have become popular. We have become accustomed to the metaphors of game environments to the point where we often don\u2019t consciously notice the weird sizes of things. Let\u2019s assume human player characters are of standard human size, that is, somewhere between 1.5 and 2 meters in height. Normal human walking speeds are in the vicinity of 3-5 km/hour, maybe twice that at the \u201cfast jog\u201d that seems to be most game characters\u2019 primary locomotion. From these, along with timing how long it takes to make various journeys in the game world, we can get rough estimates of the sizes that these worlds and objects would be if \u201csuperimposed\u201d on the real world. The numbers are surprisingly small. You could fit all of World of Warcraft\u2019s Azeroth, along with all the lands of its various expansions, several times into the county I live in\u2014it is variously estimated online at being between 200-800 square miles. A knowledgeable player could cross the original continent of Everquest\u2019s Norrath on foot in about 40 minutes. (Spoiler: it takes a little longer than that to cross real continents on foot. Try it!) Those huge, craggy, massive mountains that blot out the sky of Skyrim? The tallest is about 700 meters\u2014certainly big enough that it might be called a mountain rather than a hill (especially with that craggy shape), but nowhere near the size you\u2019d expect for its prominence in the skyline. The entire world of Skyrim covers less than 15 square miles, smaller than my town. For comparison: the base of Mt. Hood\u2014a single, moderately large volcano in Oregon\u2014covers more than 92 square miles. Whole planets in No Man\u2019s Sky are somewhere in the vicinity of twenty miles in diameter (although there are quintillions of them, so the total land area is\u2026big.) Ignoring infinite and/or near-infinite procedurally generated terrains and real-world sampled ones, I\u2019d estimate that all of the artist-designed game worlds in all computer games ever written put together would fit comfortably inside of Texas, with room left over for a lot of rattlesnakes. Things get even weirder when we consider population centers and commerce: a bustling metropolis in most of these games would have fewer than 100 residents; it\u2019s not uncommon for there to be a fully-stocked store that could literally outfit an army of adventurers in a town of eight people (and for some reason, a frighteningly large number of these shopkeepers need rats removed from their cellars). There are reasons for all these numbers, of course. The primary one, of course, is that even granting very fast travel, the vast majority of an \u201cEarth-sized world\u201d would never be seen by players. Games also have limits on how large they can be, even in an era of multi-terrabyte storage. Artists are expensive, and designing large spaces that are unlikely to be seen isn\u2019t a financially productive use of their time. Players would likely be bored if they had to spend real-world amounts of time traversing between towns or navigating about a city. For games, a better metric of world size is probably something like \u201cinterest density;\u201d some sort of measure of how many distinct places there are to visit or things to do in the game world. You can see this in city racing games: there\u2019s a lot of physical space, but it\u2019s not very detailed (almost no buildings would have interiors, for example) because the players will be literally racing by it at high speeds most of the time. On the other side, Skyrim has hundreds of points of interest and biomes scattered around it\u2019s very small (by real world standards) land area. The environment is vastly denser than the real world, giving players much less \u201ctravel time\u201d for their adventures while still creating a psychologically large sense of scale. Of course, games aren\u2019t the only uses for terrains, and for simulation purposes, real-world-analog sizes and distances are important. Microsoft Flight Simulator models, in essence, the entire (real) Earth by way of streamed geologic data. Google Earth similarly presents Earth itself in its full-scale glory. We have renderable terrain data for Mars and the Moon, as well. In some applications, there\u2019s value in being able to generate \u201creal world-like\u201d terrains at will (often enhancing or emphasizing some geologic attributes for things like pilot training in mountainous areas or spacecraft landing in unexplored terrains.) All this boils down to: it would be useful to be able to create both \u201cfull scale\u201d and \u201ccompressed\u201d terrains in order to maximize the applicability of our terrain generation engine.","title":"Size of Game Worlds"},{"location":"size_of_game_worlds/#geology","text":"We\u2019ll start with geology. As mentioned earlier, many games combine the notion of the physical shape of the land with the biological and other \u2018things\u2019 that grow or sit upon it, referring to the entire combination as a biome. For example, the Minecraft desert biome is always made up of shallow, gentle hills (reminiscent of dunes), the mountain biome is steep and (even by Minecraft standards) jagged, swamps are almost entirely flat, and so on. While these describe real-world scenarios well enough that they don\u2019t seem unnatural (at least in a world made entirely of cubes), they discount a number of possibilities. Not all mountains, jungles, hills, or forests are the same, and in many cases a single geographical entity might have many biological environments represented in it (mountains and hills, in particular, cross multiple elevations, and even with something like deserts there\u2019s amazing variablility). Still, it\u2019s handy to have a term for a particular geologic \u201cshape,\u201d so we\u2019ll call this a geome. A geome is a description of physical shape (e.g. mountainous, hilly, flat, etc.) without regard to the life or other decoration that appears on it. There are a number of mathematical mechanisms that we can use to generate natural-looking geological structures, most of them fractal in nature--that is, if we \u201czoom in\u201d on a particular sub-region of a geome, the types of shapes we see will be similar to the shape of the whole geome in structure, jaggedness, height variability, and so on. For example, \u201csmooth\u201d old mountains tend to be fairly smooth at every scale due to long-term erosion; \u201cyoung\u201d mountains tend to be sharper and rougher at both the large and the small scale. The rippling shapes of sand on desert dunes is often reminiscent of the shape of the dunes themselves. Real world fractals can maintain this self-similarity over very large ranges of size, but our synthetic ones stop at whatever the \u201cresolution\u201d of the world is on the small end (e.g. for Minecraft, the fractal nature ends at each cube. For a marching cubes/tetrahedrons implementation, it would break down each \u201ccube\u201d one more time into polygons, which would then be flat and not broken down further.) On the larger end, the structure stops at the point of the largest element of the geography: a mountain, a hill, a plain, an ocean, or whatever, although you could extend the model to whole continents or planets (and once you get planets, you\u2019ve got self similarity on huge scales again: moons orbiting planets orbiting stars orbiting galaxies orbiting clusters\u2026). Ignoring water, mountains and other large structures are the hardest part of generating terrains simply because they\u2019re large. This is particularly true for voxel terrains, because a single mountain (even a game-scale one, and definitely real-scale ones) would consist of far more 16-32 meter voxel chunks than are ever likely to be loaded at once. But even the simpler terrain objects have trouble representing spaces that are larger than a kilometer or so in a given direction. Solutions fall into several categories. The simplest is just not to allow such large terrains: even a lot of \u201copen world\u201d games have maps that cover very small amounts of actual space, usually by increasing the detail density to a level that you would never see in the real world, but that meets our expectations in games. For artist-generated worlds, the artist can combine multiple terrain or voxel objects; build the terrain as a monolithic whole, then separate them again for streaming at play time.","title":"Geology"},{"location":"size_of_game_worlds/#floating-point-precision-limits","text":"There is, as always, another problem. Coordinates in Unity (and for that matter most game engines and video cards) are stored as standard 32-bit floating point numbers. The \u201cfloating\u201d of \u201cfloating point numbers\u201d means that the decimal point can move around in the number--but the total number of bits is fixed. Which, in turn, means that there are only so many bits to go around: the larger the integer portion, the fewer bits are available to represent the decimal portion of the numbers. So, it\u2019s an inherent property of floating point numbers that the larger the absolute number, the lower the decimal precision. For most numerical uses, that\u2019s fine\u2014even desirable. We generally care about precision as a number of significant digits, and we tend to \u201cround\u201d large numbers more than small ones, anyway. If you are doing math on large numbers, the rightmost decimal digits are likely noise or uncertain, anyway. But when we\u2019re using these numbers to generate positions for things: trees, rocks, animals, mountains\u2026that lack of decimal precision is problematic. As our virtual character wanders farther and farther from the origin of their world, the \u201cgrid\u201d size on which things can be placed becomes coarser and coarser. This is because while we\u2019re considering the character\u2019s position on some global grid, the character\u2019s interest is always local--concerning the objects that are positioned around them. Unity doesn\u2019t enforce any particular interpretation of its units, but common convention sets one Unity Unit to one real-world meter (e.g. an approximately human character is between 1 and 2 Unity Units high in most game engines). A 32-bit floating point value has roughly 7 (decimal) digits of precision. So, if we\u2019re representing a position in meters, and we want at least centimeter (1/100 meter) resolution, we need to reserve two of those digits for decimal places. That leaves us about 5 decimal places of potential distance, or about 10,000 meters in which we can position things with centimeter accuracy. Since the coordinate systems are usually centered on the origin, that means our character can move (or see) about five in-game kilometers from the origin before the precision with which we can place objects drops to a tenth of a meter instead of a hundredth. Beyond 50 kilometers, we can\u2019t even place objects a meter apart reliably, and it gets worse from there. How the game engine deals with this falloff of precision after 5000 meters or so depends on the engine, but most of them will have objects \u201cjumping\u201d or \u201cshaking\u201d when placed with higher accuracy than the coordinate position allows, and certainly if you\u2019re allowing travel beyond 20 kilometers or so the errors will be too large to ignore even if you\u2019re willing to tolerate the jitter. For objects with small details, the problems get worse: render pipelines will often include steps where the model\u2019s \u201cobject\u201d coordinates are translated into \u201cworld\u201d coordinates. In such scenarios, the individual vertices of the model will be subject to the precision limits of that part of the world, and serious (and very visible) distortion will result. The financial industry has been dealing with this for decades, and their solution is usually to not use floating point numbers at all to represent currency, but rather a (large) integer number of the smallest currency unit (in the US, pennies, maybe) that needs to be represented. That doesn\u2019t help us come actual render time, because we don\u2019t have control over Unity\u2019s coordinate implementation. But we can borrow this mechanism for actually positioning things in our \u2018world\u2019 for long-term storage or generation: We can calculate positions using (say) 64-bit integer numbers of centimeters, which gives us a \u201cresolution\u201d of several quadrillion meters before we run out of space\u2014enough to represent the entire surface of any planet in our solar system to centimeter accuracy. Double-precision floats can give you trillions of meters at centimeter accuracy. Need more? Most platforms give you access to 128-bit integers, as well, which can safely be described as \u201ceffectively infinite\u201d for this purpose. If your platform provides quadruple-precision floating point numbers, you could use these, too. The \u201cinteger number of some fraction\u201d is effectively the same idea as fixed-point numbers, also provided by some libraries in large forms. Once we need to push polygons to screen, though, we\u2019re going to have to live with the limitations of 32-bit floating point numbers. And that means we need to keep moving the origin so that it stays near the player. This implies a degree of chunking even to non-voxel worlds (in the voxel case, the chunks are handily already provided!). When a certain distance is reached, the player and every \u201cnearby\u201d object will be translated or reloaded relative to a new origin point closer to the player. Finally, consider a character standing on a mountaintop on a clear day. On Earth, that character would be able to see perhaps a hundred kilometers in any direction. This seems to throw a wrench into our \u201ceverything has to be within 5000 meters of the player\u201d rule. There are all sorts of reasons why this scenario is hard, not the least of which is that there\u2019s an awful lot of \u201cthere\u201d there. But once we observe that the character isn\u2019t going to be seeing centimeter-sized details from 5km away, nor meter-sized ones at 100km, it becomes a little easier. We\u2019re going to have to solve level-of-detail (LOD) issues, anyway, so we just need to be aware that floating-point precision is going to put an upper bound on how precise each detail level can be--probably a weaker bound than the actual amount of space, though. If the world is divided into 1km square terrain pieces, our mountaintop viewer can see potentially a hundred thousand of them at once, which means each one can\u2019t have many polygons, anyway.","title":"Floating Point Precision Limits"},{"location":"size_of_game_worlds/#level-of-detail","text":"...and that brings up the next point. It's fairly common to have terrain rendered on top of an (x,z) mesh where the vertices are one meter apart. Unity uses \"unity units\", which have no explicit size out of context, but by common convention many modelers base it on a 1UU = 1M scale, so a typical human is somewhere between one and two units in height, depending on age, gender, physique, etc. The continental United States is approximately 4500 x 2500 kilometers, so it would have something over eleven trillion \"vertices\" if measured on a coordinate grid. Of course, at that scale the curvature of the Earth would make a mess of pure cartesian coordinates, but in many applications\u2014even some real world ones\u2014that can be ignored. Real world map data at that scale does exist, for example see the USDA Geospatial Data Gateway for LiDAR maps of most of the United States at one meter resolution. But these data sets are very large: even if you could somehow represent each height element as a single byte, that's over eleven terabytes for the U.S. alone. Technical discussions always run the risk of rapidly becoming outdated by the march of technological progress, but at least in mid-2021, it's reasonable to say that no video card is going to push 11 terabytes of coordinate data (nor the 22 trillion resulting tesselated polygons) at all, much less in real time. And never mind the GPU: very, very few modern computers are likely sporting 11 TB of RAM, and while a few folks may have that level of secondary storage, they're going to be in a distinct minority, as well. So there are compromises to be made, depending on the applicaton.","title":"Level of Detail"},{"location":"size_of_game_worlds/#reduce-the-data-set","text":"As a starting point, consider whether we need to store that much data at all. Flight simulators, and other scenarios where the player isn't going to get a good look at terrain details can probably get by with much less than 1m resolution. If you can reduce your grid to, say, ten meter spacing, your 11 TB dataset is now a mere few hundred GB, and if you can use hundred meter spacing, you're within the sizes acceptable for a downloadable game these days. Alternatively, even in a flight simulator, the player isn't going to be able to see most of the US at any given moment--or for most flights, at all. Streaming just the needed data from a large cloud source might work, especially in combination with level of detail calculations. For example, your game might need 1m resolution near airports, but only 10m resolution for most of a flight where the plane is at 30,000 feet altitude. Similarly, GPS mapping systems meant for automobile navigation need basically no data at all for areas not on a roadway. Even better, roads have relatively few configurations in the real world, so a hundred miles of interstate through the central plains might take only a few hundred bytes of data to accurately represent. A curving mountain road or logging road might require a much higher information density, but they make up a relatively small percentage of the total roads. For game worlds that don't represent real worlds, we have additional options. There are numerous mechanisms for generating \"random\" terrains from seed values, or for using seed values to 'search' into some mathematical space, such as Perlin noise. In both cases, the seed values can be generated hierarchically from a higher level seed. For example, use one seed integer for the world, use that to generate the seed values for quarters of the world, subdivide each of those into quarters using those seeds, and so on, in a space partitioning algorithm. Since this generates a binary (really quadrary) tree, the \"deepest\" seeds can be generated from the initial seed in a logarithmic number of steps; a few dozen iterations will get us to US-sized spaces with ease. Even easier is to skit the seed generation (or use only one \"world\" seed) and just use the coordinates of the desired location as the \"seed\" or lookup key. Minecraft does this, using the world coordinates to look up a position in a Perlin (or similar) continuous 3D noise function to generate its terrain. Non-voxel games, or games in which 3D overhangs do not appear, can use a simpler 2D noise function. If the player cannot modify the world, using these generation methods means that no terrain data need be stored at all; it can always be regenerated (and on modern systems, possibly even done on the GPU itself via shader) based on the player's (or some other entity's) position. If player interations are limited to surface elements (chopping down trees, picking up rocks, killing monsters, etc.), only the \"things\" in the world need to be stored long term. Even if the player can modify the world's terrain itself (digging, building, blasting, whatever), it is unlikely that the vast majority of \"chunks\" in the world will remain forever untouched by the player, and only those chunks that are modified need to be stored. It's not uncommon for even that storage to be time- or space-limited; returning to a modified terrain after a long absence (or after modifying lots of other terrain in the interim) will in some games result in the player's modifications being lost: the game trades off the likelyhood that the player will return to a long-ago-important location against limiting the size of the \"modified chunks\" cache. (I'm suddenly envisioning a hypothetical game in which players smash asteroids into planets from space, thus violating the \"players only modify things really near themselves\" rule, but that'll take a different design entirely.)","title":"Reduce the data set"},{"location":"size_of_game_worlds/#reduce-the-level-of-detail","text":"Somewhat orthogonal to the question of how much data is being used to store the world, is the question of how much data is being used to store the parts of it that the player can actually see at any given moment. The answer might be \"all of it;\" Astroneer , No Man's Sky and Empyrion all feature gameplay elements where a player approaches a planet from space, and at least during these ascent/descent sequences can see a significant fraction of the entire surface of the planet. All of them make visibly obvious simplifications to the world in order to pull it off. Most notably, terrain \"snaps\" into more and more detailed configurations as the player approaches the surface, and \"ground\" clutter things like trees, plants, objects, and animals either do not appear at all until landing, or only when the player is extremely close to the ground. ( No Man's Sky uses the same \"hide the details\" mechanism even for relatively low flight, unless the player's spacecraft moves extremely slowly with respect to the terrain.) More typically, the player is on the ground, and their vision will be limited by any nearby objects, the terrain itself, the horizon (real or virtual), and other factors. Video games often supplement this with fog or other visibility-limiting elements, but we're interested here in the \"clear day\" scenarios. The Internet\u2014which would never lie to me\u2014tells me that the horizon as viewed from a height h above the ground on a flat plain or ocean, will be a distance d away based on: $$ d = 10000 * \\sqrt{h / 6.752} $$ Where d and h are in centimeters. (Drop the 10K multiplier to get d in kilometers, since it will typically be large). For an average height human standing up, that's going to be a little less than 5km (or 3 miles, but games almost always use metric internally). Which isn't too bad. A circle with that radius has about 78 million square meters, most of which will be out of sight behind or to the side of the player. It's still too much to draw: If we can \"see\" 25 million of them, and they have two polygons each, that's about 4.5 billion polygons we'll need to draw per second to get 90 fps. A fairly high end modern video card can do that under optimal circumsances, but it doesn't leave us much polygon budget for the rest of the game, nor any real support for more typical hardware. It's also (probably coincidentally) just about the range at which floating point errors will start being visible. And that's a best case. Add even a few dozen centimeters (say, a character jumping), and you'll get a few hundred meters of additional view. Let the character be standing on a mountainside at 3000 meters, and they'll be able to see more than 200 kilometers. That's reversable, too; a player on a flat plain will be able to see at least part of a 3000 meter mountain even if it's 200 km away from them. Even that's hardly a worst case. Earth's Mt. Everest is almost three times that high, even the old and eroded Cascade Mountains in the US Pacific Northwest have several volcanos well over the 3000 meter mark. Lower-gravity worlds are likely to have features many times larger still. As we discussed above, though, the primary problem here are those 1m resolution polygons. At the opposite end of the equation, I could represent the entire United States (badly) with a single polygon. It wouldn't capture most of the details, but with a reasonable texture on it, and viewed from, say, the moon or high orbit, it might work fine. The \"Secret Sauce,\" of course, is to mix the levels. Things nearby the player should be modelled at higher resolutions, things further away can be modelled at progressively lower resolutions the farther away they are. It would probably be possible to build a continuous version of this (where every polygon has it's vertex resolution determined by how far it is from the player), but more generally LOD systems tend to be zoned. For example, terrain within a kilometer of the player is at 1meter resolution, then 2 meter resolution for another kilometer, 16 meter resolution for another few kilometers, and 128 meter resolution beyond that (these numbers are made up for example and will be highly dependent on the particular engine and game.) Zones will usually \"round\" to chunks of some sort. For example, if we're using Unity Terrain objects with 512x512 meter edges, it would be reasonable to have the Terrain in which the character is located be at 1meter resolution, as well as the nine or twenty-four Terrains encircling that one. Beyond that, the Terrain objects may be built at lower resolutions (and possibly higher sizes) out to whatever maximum visibility we allow. As the player moves and leaves their current Terrain, the ones that are now \"too far\" from the player are discarded in favor of lower-resolution versions, and new ones that have come \"in range\" are generated or re-generated at higher resolution. Note : Unity terrains have an internal level of detail that describes their shapes using a minimum set of polygons: rough areas have more polygons than smooth ones (which discard vertices which would just be in a plane described by the surrounding ones). This is done automatically and internally as the shapes of the terrain change, and scales with the scale of the terrain. So we get this extra optimization \"for free,\" at least until our terrains become too complex. We may be able to apply additional optimizations: If the game does not allow a player to move underwater, it's reasonable to simplify \"undersea\" terrain significantly, since the player will never see it. A very sophisticated engine might be able to determine that large amounts of terrain are \"over the hill,\" occluded by a mountain, or otherwise blocked by the existing terrain from the player's view point, and not generate that space at all until needed.","title":"Reduce the Level of Detail"}]}