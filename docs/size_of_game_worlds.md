#  Size of Game Worlds

By and large, game worlds are tiny.   Very, very tiny.    This includes the “huge open worlds” that have become popular.    We have become accustomed to the metaphors of game environments to the point where we often don’t consciously notice the weird sizes of things.

Let’s assume human player characters are of standard human size, that is, somewhere between 1.5 and 2 meters in height.  Normal human walking speeds are in the vicinity of 3-5 km/hour, maybe twice that at the “fast jog” that seems to be most game characters’ primary locomotion.  From these, along with timing how long it takes to make various journeys in the game world, we can get rough estimates of the sizes that these worlds and objects would be if “superimposed” on the real world.

The numbers are surprisingly small.   You could fit all of World of Warcraft’s Azeroth, along with all the lands of its various expansions, several times into the county I live in—it is variously estimated online at being between 200-800 square miles.   A knowledgeable player could cross the original continent of Everquest’s Norrath on foot in about 40 minutes.   Those huge, craggy, massive mountains that blot out the sky of Skyrim?   The tallest is about 700 meters—certainly big enough that it might be called a mountain rather than a hill (especially with that craggy shape), but nowhere near the size you’d expect for its prominence in the skyline.    The entire world of Skyrim covers less than 15 square miles, smaller than my town.  For comparison: the base of Mt. Hood—a single, moderately large volcano in Washington State —covers more than 92 square miles.   Whole planets in No Man’s Sky are somewhere in the vicinity of twenty miles in diameter (although there are quintillions of them, so the total land area is…big.)

Ignoring infinite and/or near-infinite procedurally generated terrains and real-world sampled ones, I’d estimate that all of the artist-designed game worlds in all computer games ever written put together would fit comfortably inside of Texas, with room left over for a lot of rattlesnakes.

Things get even weirder when we consider population centers and commerce:   a bustling metropolis in most of these games would have fewer than 100 residents; it’s not uncommon for there to be a fully-stocked store that could literally outfit an army of adventurers in a town of eight people (for some reason, a frighteningly large number of these shop keepers need rats removed from their cellars.)

There are reasons for all these numbers, of course.    The primary one, of course, is that barring very fast travel, the vast majority of an “Earth-sized world” would never be seen by players.  Games also have limits on how large they can be, even in an era of multi-terrabyte storage.   Artists are expensive, and designing large spaces that are unlikely to be seen isn’t a financially productive use of their time.    Players would likely be bored if they had to spend real-world amounts of time traversing between towns or navigating about a city.   

For games, a better metric of world size is probably something like “interest density;” some sort of measure of how many distinct places there are to visit or things to do in the game world.   You can see this in city racing games:  there’s a lot of physical space, but it’s not very detailed (almost no buildings would have interiors, for example) because the players will be literally racing by it at high speeds most of the time.    On the other side, Skyrim has hundreds of points of interest and biomes scattered around it’s very small (by real world standards) land area.   The environment is vastly denser than the real world, giving players much less “travel time” for their adventures while still creating a psychologically large sense of scale.

Of course, games aren’t the only uses for terrains, and for simulation purposes, real-world-analog sizes and distances are important.   Microsoft Flight Simulator models, in essence, the entire (real) Earth by way of streamed geologic data.   Google Earth similarly presents Earth itself in its full-scale glory.   We have renderable terrain data for Mars and the Moon, as well.    In some applications, there’s value in being able to generate “real world-like” terrains at will (often enhancing or emphasizing some geologic attributes for things like pilot training in mountainous areas or spacecraft landing in unexplored terrains.)

All this boils down to:  it would be useful to be able to create both “full scale” and “compressed” terrains in order to maximize the applicability of our terrain generation engine.

## Geology

We’ll start with geology.   As mentioned earlier, many games combine the notion of the physical shape of the land with the biological and other ‘things’ that grow or sit upon it, referring to the entire combination as a biome.   For example, the Minecraft desert biome is always made up of shallow, gentle hills (reminiscent of dunes), the mountain biome is steep and (even by Minecraft standards) jagged, swamps are almost entirely flat, and so on.    While these describe real-world scenarios well enough that they don’t seem unnatural (at least in a world made entirely of cubes), they discount a number of possibilities.    Not all mountains, jungles, hills, or forests are the same, and in many cases a single geographical entity might have many biological environments represented in it (mountains and hills, in particular, cross multiple elevations, and even with something like deserts there’s amazing variablility).

Still, it’s handy to have a term for a particular geologic “shape,” so we’ll call this a geome.   A geome is a description of physical shape (e.g. mountainous, hilly, flat, etc.) without regard to the life or other decoration that appears on it.

There are a number of mathematical mechanisms that we can use to generate natural-looking geological structures, most of them fractal in nature--that is, if we “zoom in” on a particular sub-region of a geome, the types of shapes we see will be similar to the shape of the whole geome in structure, jaggedness, height variability, and so on.      For example, “smooth” old mountains tend to be fairly smooth at every scale due to long-term erosion; “young” mountains tend to be sharper and rougher at both the large and the small scale.    The rippling shapes of sand on desert dunes is often reminiscent of the shape of the dunes themselves.

Real world fractals can maintain this self-similarity over very large ranges of size, but our synthetic ones stop at whatever the “resolution” of the world is on the small end (e.g. for Minecraft, the fractal nature ends at each cube.   For a marching cubes/tetrahedrons implementation, it would break down each “cube” one more time into polygons, which would then be flat and not broken down further.)

 On the larger end, the structure stops at the point of the largest element of the geography:  a mountain, a hill, a plain, an ocean, or whatever, although you could extend the model to whole continents or planets (and once you get planets, you’ve got self similarity on huge scales again: moons orbiting planets orbiting stars orbiting galaxies orbiting clusters…).

Ignoring water, mountains and other large structures are the hardest part of generating terrains simply because they’re large.   This is particularly true for voxel terrains, because a single mountain (even a game-scale one, and definitely real-scale ones) would consist of far more 16-32 meter voxel chunks than are ever likely to be loaded at once.     But even the simpler terrain objects have trouble representing spaces that are larger than a kilometer or so in a given direction.

Solutions fall into several categories.    The simplest is just not to allow such large terrains:  even a lot of “open world” games have maps that cover very small amounts of actual space, usually by increasing the detail density to a level that you would never see in the real world, but that meets our expectations in games.    For artist-generated worlds, the artist can combine multiple terrain or voxel objects; build the terrain as a monolithic whole, then separate them again for streaming at play time.

## Floating Point Precision Limits

There is, as always, another problem.  Coordinates in Unity (and for that matter most game engines and video cards) are stored as standard 32-bit floating point numbers.   The “floating” of “floating point numbers” means that the decimal point can move around in the number--but the total number of bits is fixed.  Which, in turn, means that there are only so many bits to go around:  the larger the integer portion, the fewer bits are available to represent the decimal portion of the numbers.  So, it’s an inherent property of floating point numbers that the larger the absolute number, the lower the decimal precision.

For most numerical uses, that’s fine—even desirable.   We generally care about precision as a number of significant digits, and we tend to “round” large numbers more than small ones, anyway.   If you are doing math on large numbers, the rightmost decimal digits are likely noise or uncertain, anyway.

But when we’re using these numbers to generate positions for things: trees, rocks, animals, mountains…that lack of decimal precision is problematic.     As our virtual character wanders farther and farther from the origin of their world, the “grid” size on which things can be placed becomes coarser and coarser.    This is because while we’re considering the character’s position on some global grid, the character’s interest is always local--concerning the objects that are positioned around them.

Unity doesn’t enforce any particular interpretation of its units, but common convention sets one Unity Unit to one real-world meter (e.g. an approximately human character is between 1 and 2 Unity Units high in most game engines).    

A 32-bit floating point value has roughly 7 (decimal) digits of precision.    So, if we’re representing a position in meters, and we want at least centimeter (1/100 meter) resolution, we need to reserve two of those digits for decimal places.    That leaves us about 5 decimal places of potential distance, or about 10,000 meters in which we can position things with centimeter accuracy.   Since the coordinate systems are usually centered on the origin, that means our character can move (or see) about five in-game kilometers from the origin before the precision with which we can place objects drops to a tenth of a meter instead of a hundredth.   Beyond 50 kilometers, we can’t even place objects a meter apart reliably, and it gets worse from there.

How the game engine deals with this falloff of precision after 5000 meters or so depends on the engine, but most of them will have objects “jumping” or “shaking” when placed with higher accuracy than the coordinate position allows, and certainly if you’re allowing travel beyond 20 kilometers or so the errors will be too large to ignore even if you’re willing to tolerate the jitter.

For objects with small details, the problems get worse:  render pipelines will often include steps where the model’s “object” coordinates are translated into “world” coordinates.  In such scenarios, the individual vertices of the model will be subject to the precision limits of that part of the world, and serious (and very visible) distortion will result.

The financial industry has been dealing with this for decades, and their solution is usually to not use floating point numbers at all to represent currency, but rather a (large) integer number of the smallest currency unit (in the US, pennies, maybe) that needs to be represented.

That doesn’t help us come actual render time, because we don’t have control over Unity’s coordinate implementation.   But we can borrow this mechanism for actually positioning things in our ‘world’ for long-term storage or generation:   We can calculate positions using (say) 64-bit integer numbers of centimeters, which gives us a “resolution” of several quadrillion meters before we run out of space – enough to represent the entire surface of any planet in our solar system to centimeter accuracy.   Double-precision floats can give you trillions of meters at centimeter accuracy.   Need more?   Most platforms give you access to 128-bit integers, as well, which can safely be described as “effectively infinite” for this purpose.  If your platform provides quadruple-precision floating point numbers, you could use these, too.  The “integer number of some fraction” is effectively the same idea as fixed-point numbers, also provided by some libraries in large forms.

Once we need to push polygons to screen, though, we’re going to have to live with the limitations of 32-bit floating point numbers.  And that means we need to keep moving the origin so that it stays near the player.   This implies a degree of chunking even to non-voxel worlds (in the voxel case, the chunks are handily already provided!).    When a certain distance is reached, the player and every “nearby” object will be translated or reloaded relative to a new origin point closer to the player.

Finally, consider a character standing on a mountaintop on a clear day.   On Earth, that character would be able to see perhaps a hundred kilometers in any direction.    This seems to throw a wrench into our “everything has to be within 5000 meters of the player” rule.   There are all sorts of reasons why this scenario is hard, not the least of which is that there’s an awful lot of “there” there.   But once we observe that the character isn’t going to be seeing centimeter-sized details from 5km away, nor meter-sized ones at 100km, it becomes a little easier.    We’re going to have to solve level-of-detail (LOD) issues, anyway, so we just need to be aware that floating-point precision is going to put an upper bound on how precise each detail level can be--probably a weaker bound than the actual amount of space, though.    If the world is divided into 1km square terrain pieces, our mountaintop viewer can see potentially a hundred thousand of them at once, which means each one can’t have many polygons, anyway.


